Wed May 10 09:11:01 UTC 2017 Starting master on hadoop-master
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30718
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2017-05-10 09:11:02,574 INFO  [main] util.VersionInfo: HBase 0.98.24-hadoop2
2017-05-10 09:11:02,575 INFO  [main] util.VersionInfo: Source code repository git://buildbox/data/src/hbase revision=9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6
2017-05-10 09:11:02,575 INFO  [main] util.VersionInfo: Compiled by apurtell on Thu Dec 22 02:36:05 UTC 2016
2017-05-10 09:11:02,575 INFO  [main] util.VersionInfo: From source with checksum 286dfd46f04c92066a514339558c8bf2
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/root/hbase98/bin/../logs
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:LESSCLOSE=/usr/bin/lesspipe %s %s
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/root/hbase98/bin/../logs -Dhbase.log.file=hbase--master-hadoop-master.log -Dhbase.home.dir=/root/hbase98/bin/.. -Dhbase.id.str= -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/local/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/root/hbase98/bin/..
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HOSTNAME=hadoop-master
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:PWD=/root/hbase98
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase--master.znode
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/local/hadoop
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/local/hadoop/lib/native
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2017-05-10 09:11:02,821 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2017-05-10 09:11:02,822 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HOME=/root
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:LESSOPEN=| /usr/bin/lesspipe %s
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase--master.autorestart
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase--master-hadoop-master.log
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase--master-hadoop-master
2017-05-10 09:11:02,823 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=
2017-05-10 09:11:02,824 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.121-b00
2017-05-10 09:11:02,825 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/root/hbase98/bin/../logs, -Dhbase.log.file=hbase--master-hadoop-master.log, -Dhbase.home.dir=/root/hbase98/bin/.., -Dhbase.id.str=, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/local/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2017-05-10 09:11:02,896 DEBUG [main] master.HMaster: master/hadoop-master/172.18.0.2:60000 HConnection server-to-server retries=350
2017-05-10 09:11:03,066 INFO  [main] ipc.RpcServer: master/hadoop-master/172.18.0.2:60000: started 10 reader(s).
2017-05-10 09:11:03,188 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2017-05-10 09:11:03,240 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-05-10 09:11:03,240 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2017-05-10 09:11:03,921 INFO  [main] master.HMaster: hbase.rootdir=hdfs://hadoop-master:9000/hbase, hbase.cluster.distributed=true
2017-05-10 09:11:03,925 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-05-10 09:11:03,960 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=hadoop-master
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_121
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2017-05-10 09:11:03,965 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-59-generic
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2017-05-10 09:11:03,966 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/root/hbase98
2017-05-10 09:11:03,967 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@27440fb4
2017-05-10 09:11:03,980 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:03,992 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:04,096 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:04,097 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:04,098 DEBUG [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2017-05-10 09:11:04,098 INFO  [main] util.RetryCounter: Sleeping 1000ms before retry #0...
2017-05-10 09:11:04,198 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:04,198 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:05,298 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:05,299 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:05,399 DEBUG [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2017-05-10 09:11:05,399 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:05,399 INFO  [main] util.RetryCounter: Sleeping 2000ms before retry #1...
2017-05-10 09:11:05,399 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:05,500 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:05,500 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:06,601 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:06,601 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:06,701 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:06,702 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:06,802 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:06,802 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:07,903 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:07,903 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:08,003 DEBUG [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2017-05-10 09:11:08,003 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:08,003 INFO  [main] util.RetryCounter: Sleeping 4000ms before retry #2...
2017-05-10 09:11:08,004 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:08,104 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:08,104 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:09,205 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:09,205 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:09,306 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:09,306 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:09,407 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:09,408 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:10,509 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:10,509 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:10,610 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:10,610 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:10,711 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:10,711 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:11,812 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:11,812 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:11,912 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:11,913 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:12,013 DEBUG [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2017-05-10 09:11:12,013 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:12,013 INFO  [main] util.RetryCounter: Sleeping 8000ms before retry #3...
2017-05-10 09:11:12,014 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:13,114 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:13,114 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:13,215 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:13,215 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:13,316 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:13,316 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:14,417 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:14,417 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:14,517 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:14,518 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:14,618 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:14,619 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:15,719 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:15,719 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:15,820 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:15,820 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:15,921 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:15,921 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:17,021 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:17,022 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:17,122 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:17,122 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:17,223 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:17,223 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:18,324 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:18,325 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:18,426 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:18,427 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:18,528 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:18,528 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:19,629 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:19,630 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:19,731 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:19,731 WARN  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:19,831 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:19,832 WARN  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:20,932 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:20,932 WARN  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2017-05-10 09:11:21,033 DEBUG [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2017-05-10 09:11:21,033 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:11:21,033 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper create failed after 4 attempts
2017-05-10 09:11:21,133 INFO  [main] zookeeper.ZooKeeper: Session: 0x0 closed
2017-05-10 09:11:21,134 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-10 09:11:21,134 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster
	at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:3150)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:199)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:135)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:127)
	at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:3164)
Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.createNonSequential(RecoverableZooKeeper.java:575)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.create(RecoverableZooKeeper.java:554)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1207)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1185)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.createBaseZNodes(ZooKeeperWatcher.java:193)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:177)
	at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:561)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:3145)
	... 5 more
Wed May 10 09:12:32 UTC 2017 Starting master on hadoop-master
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30718
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2017-05-10 09:12:33,239 INFO  [main] util.VersionInfo: HBase 0.98.24-hadoop2
2017-05-10 09:12:33,239 INFO  [main] util.VersionInfo: Source code repository git://buildbox/data/src/hbase revision=9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6
2017-05-10 09:12:33,239 INFO  [main] util.VersionInfo: Compiled by apurtell on Thu Dec 22 02:36:05 UTC 2016
2017-05-10 09:12:33,239 INFO  [main] util.VersionInfo: From source with checksum 286dfd46f04c92066a514339558c8bf2
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/root/hbase98/bin/../logs
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:LESSCLOSE=/usr/bin/lesspipe %s %s
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/root/hbase98/bin/../logs -Dhbase.log.file=hbase--master-hadoop-master.log -Dhbase.home.dir=/root/hbase98/bin/.. -Dhbase.id.str= -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/local/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/root/hbase98/bin/..
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HOSTNAME=hadoop-master
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:PWD=/root/hbase98
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase--master.znode
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2017-05-10 09:12:33,481 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2017-05-10 09:12:33,482 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2017-05-10 09:12:33,482 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/local/hadoop
2017-05-10 09:12:33,482 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/local/hadoop/lib/native
2017-05-10 09:12:33,482 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2017-05-10 09:12:33,482 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:HOME=/root
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:LESSOPEN=| /usr/bin/lesspipe %s
2017-05-10 09:12:33,483 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase--master.autorestart
2017-05-10 09:12:33,484 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:
2017-05-10 09:12:33,484 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase--master-hadoop-master.log
2017-05-10 09:12:33,484 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase--master-hadoop-master
2017-05-10 09:12:33,484 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=
2017-05-10 09:12:33,485 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.121-b00
2017-05-10 09:12:33,485 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/root/hbase98/bin/../logs, -Dhbase.log.file=hbase--master-hadoop-master.log, -Dhbase.home.dir=/root/hbase98/bin/.., -Dhbase.id.str=, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/local/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2017-05-10 09:12:33,559 DEBUG [main] master.HMaster: master/hadoop-master/172.18.0.2:60000 HConnection server-to-server retries=350
2017-05-10 09:12:33,755 INFO  [main] ipc.RpcServer: master/hadoop-master/172.18.0.2:60000: started 10 reader(s).
2017-05-10 09:12:33,842 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2017-05-10 09:12:33,898 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-05-10 09:12:33,898 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2017-05-10 09:12:34,464 INFO  [main] master.HMaster: hbase.rootdir=hdfs://hadoop-master:9000/hbase, hbase.cluster.distributed=true
2017-05-10 09:12:34,468 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-05-10 09:12:34,502 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=hadoop-master
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_121
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2017-05-10 09:12:34,507 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-59-generic
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2017-05-10 09:12:34,508 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/root/hbase98
2017-05-10 09:12:34,509 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@2c45f9ae
2017-05-10 09:12:34,521 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:12:34,529 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-10 09:12:34,646 INFO  [main-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bf1a19f7c0000, negotiated timeout = 90000
2017-05-10 09:12:35,104 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2017-05-10 09:12:35,104 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2017-05-10 09:12:35,546 INFO  [master:hadoop-master:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-05-10 09:12:35,691 INFO  [master:hadoop-master:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-05-10 09:12:35,702 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2017-05-10 09:12:35,702 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-10 09:12:35,766 INFO  [master:hadoop-master:60000] http.HttpServer: Jetty bound to port 60010
2017-05-10 09:12:35,766 INFO  [master:hadoop-master:60000] mortbay.log: jetty-6.1.26
2017-05-10 09:12:36,643 INFO  [master:hadoop-master:60000] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2017-05-10 09:12:37,061 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2017-05-10 09:12:37,067 INFO  [master:hadoop-master:60000] master.ActiveMasterManager: Registered Active Master=hadoop-master,60000,1494407554046
2017-05-10 09:12:37,145 INFO  [master:hadoop-master:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-10 09:12:38,148 INFO  [master:hadoop-master:60000] util.FSUtils: Created version file at hdfs://hadoop-master:9000/hbase with version=8
2017-05-10 09:12:38,368 DEBUG [master:hadoop-master:60000] util.FSUtils: Created cluster ID file at hdfs://hadoop-master:9000/hbase/hbase.id with ID: ab85833e-cbd6-4ae1-96c6-4eee71046143
2017-05-10 09:12:38,484 INFO  [master:hadoop-master:60000] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2017-05-10 09:12:38,510 INFO  [master:hadoop-master:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2017-05-10 09:12:38,593 INFO  [master:hadoop-master:60000] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://hadoop-master:9000/hbase Table name == hbase:meta
2017-05-10 09:12:38,792 INFO  [master:hadoop-master:60000] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2017-05-10 09:12:38,936 INFO  [master:hadoop-master:60000] wal.FSHLog: New WAL /hbase/data/hbase/meta/1588230740/WALs/hlog.1494407558843
2017-05-10 09:12:38,968 DEBUG [master:hadoop-master:60000] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2017-05-10 09:12:39,053 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Created cacheConfig for info: CacheConfig:disabled
2017-05-10 09:12:39,087 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-05-10 09:12:39,141 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2017-05-10 09:12:39,141 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2017-05-10 09:12:39,144 DEBUG [master:hadoop-master:60000] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://hadoop-master:9000/hbase/data/hbase/meta/1588230740
2017-05-10 09:12:39,148 INFO  [master:hadoop-master:60000] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2017-05-10 09:12:39,149 DEBUG [master:hadoop-master:60000] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-05-10 09:12:39,149 DEBUG [master:hadoop-master:60000] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2017-05-10 09:12:39,150 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncNotifier] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000-WAL.AsyncNotifier] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncNotifier exiting
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncSyncer0] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000-WAL.AsyncSyncer0] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer0 exiting
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncSyncer1] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000-WAL.AsyncSyncer1] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer1 exiting
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncSyncer2] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000-WAL.AsyncSyncer2] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer2 exiting
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncSyncer3] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-05-10 09:12:39,150 INFO  [master:hadoop-master:60000-WAL.AsyncSyncer3] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer3 exiting
2017-05-10 09:12:39,150 DEBUG [master:hadoop-master:60000-WAL.AsyncSyncer4] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-05-10 09:12:39,151 INFO  [master:hadoop-master:60000-WAL.AsyncSyncer4] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncSyncer4 exiting
2017-05-10 09:12:39,151 DEBUG [master:hadoop-master:60000-WAL.AsyncWriter] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-05-10 09:12:39,151 INFO  [master:hadoop-master:60000-WAL.AsyncWriter] wal.FSHLog: master:hadoop-master:60000-WAL.AsyncWriter exiting
2017-05-10 09:12:39,151 DEBUG [master:hadoop-master:60000] wal.FSHLog: Closing WAL writer in hdfs://hadoop-master:9000/hbase/data/hbase/meta/1588230740/WALs
2017-05-10 09:12:39,293 DEBUG [master:hadoop-master:60000] wal.FSHLog: Moved 1 WAL file(s) to /hbase/data/hbase/meta/1588230740/oldWALs
2017-05-10 09:12:39,434 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Wrote descriptor into: hdfs://hadoop-master:9000/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-05-10 09:12:39,503 INFO  [master:hadoop-master:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2017-05-10 09:12:39,516 DEBUG [master:hadoop-master:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2017-05-10 09:12:39,519 INFO  [master:hadoop-master:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-05-10 09:12:39,520 INFO  [master:hadoop-master:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2017-05-10 09:12:39,521 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Fetching table descriptors from the filesystem.
2017-05-10 09:12:39,577 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x40783bcb connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-10 09:12:39,578 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@14d139ee
2017-05-10 09:12:39,578 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:12:39,579 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-slave2.hadoop/172.18.0.4:2181, initiating session
2017-05-10 09:12:39,607 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-slave2.hadoop/172.18.0.4:2181, sessionid = 0x25bf1a19fb60000, negotiated timeout = 90000
2017-05-10 09:12:39,622 DEBUG [master:hadoop-master:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5b14904d
2017-05-10 09:12:39,772 INFO  [master:hadoop-master:60000] master.HMaster: Server active/primary master=hadoop-master,60000,1494407554046, sessionid=0x5bf1a19f7c0000, setting cluster-up flag (Was=false)
2017-05-10 09:12:40,036 INFO  [master:hadoop-master:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-05-10 09:12:40,037 DEBUG [master:hadoop-master:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:hadoop-master,60000,1494407554046
2017-05-10 09:12:40,156 INFO  [master:hadoop-master:60000] master.MasterCoprocessorHost: System coprocessor loading is enabled
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-hadoop-master:60000, corePoolSize=10, maxPoolSize=10
2017-05-10 09:12:40,161 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-hadoop-master:60000, corePoolSize=1, maxPoolSize=1
2017-05-10 09:12:40,162 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-05-10 09:12:40,163 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-10 09:12:40,164 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@86a8fa1
2017-05-10 09:12:40,164 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-10 09:12:40,164 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-10 09:12:40,213 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bf1a19f7c0004, negotiated timeout = 90000
2017-05-10 09:12:40,330 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-05-10 09:12:40,332 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-05-10 09:12:40,333 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-05-10 09:12:40,334 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-05-10 09:12:40,335 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-05-10 09:12:40,335 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-10 09:12:40,485 INFO  [FifoRpcScheduler.handler1-thread-3] master.ServerManager: Registering server=hadoop-master,60020,1494407557387
2017-05-10 09:12:40,485 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:40,485 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 150 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-10 09:12:40,485 INFO  [FifoRpcScheduler.handler1-thread-2] master.ServerManager: Registering server=hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:40,491 INFO  [FifoRpcScheduler.handler1-thread-3] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-10 09:12:40,491 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-10 09:12:40,491 INFO  [FifoRpcScheduler.handler1-thread-2] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-10 09:12:40,535 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 200 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-10 09:12:40,566 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:40,567 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:40,567 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-master,60020,1494407557387
2017-05-10 09:12:42,038 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1703 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-10 09:12:43,541 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 3206 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-10 09:12:44,844 INFO  [master:hadoop-master:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4509 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-05-10 09:12:44,850 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387 belongs to an existing region server
2017-05-10 09:12:44,850 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923 belongs to an existing region server
2017-05-10 09:12:44,850 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979 belongs to an existing region server
2017-05-10 09:12:45,664 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2017-05-10 09:12:45,681 DEBUG [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2017-05-10 09:12:45,684 DEBUG [master:hadoop-master:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=hadoop-slave1.hadoop,60020,1494407556923; 3 (online=3, available=3) available servers, forceNewPlan=false
2017-05-10 09:12:45,684 INFO  [master:hadoop-master:60000] master.AssignmentManager: Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-10 09:12:45,684 DEBUG [master:hadoop-master:60000] zookeeper.ZKAssign: master:60000-0x5bf1a19f7c0000, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-05-10 09:12:45,713 DEBUG [master:hadoop-master:60000] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2017-05-10 09:12:45,763 INFO  [master:hadoop-master:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:45,764 INFO  [master:hadoop-master:60000] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1494407565684, server=null} to {1588230740 state=PENDING_OPEN, ts=1494407565763, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:45,764 DEBUG [master:hadoop-master:60000] master.ServerManager: New admin connection to hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:45,843 INFO  [master:hadoop-master:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2017-05-10 09:12:45,870 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-slave1.hadoop,60020,1494407556923, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1494407565763, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:45,871 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1494407565763, server=hadoop-slave1.hadoop,60020,1494407556923} to {1588230740 state=OPENING, ts=1494407565871, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:46,240 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-slave1.hadoop,60020,1494407556923, region=1588230740, current_state={1588230740 state=OPENING, ts=1494407565871, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:46,240 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1494407565871, server=hadoop-slave1.hadoop,60020,1494407556923} to {1588230740 state=OPEN, ts=1494407566240, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:46,242 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from hadoop-slave1.hadoop,60020,1494407556923; deleting unassigned node
2017-05-10 09:12:46,256 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x5bf1a19f7c0000, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-05-10 09:12:46,257 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1494407566240, server=hadoop-slave1.hadoop,60020,1494407556923}
2017-05-10 09:12:46,257 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:46,258 INFO  [master:hadoop-master:60000] master.HMaster: hbase:meta assigned=1, rit=false, location=hadoop-slave1.hadoop,60020,1494407556923
2017-05-10 09:12:46,319 INFO  [master:hadoop-master:60000] catalog.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2017-05-10 09:12:46,320 INFO  [master:hadoop-master:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2017-05-10 09:12:46,328 DEBUG [master:hadoop-master:60000] zookeeper.ZKAssign: master:60000-0x5bf1a19f7c0000, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleting any existing unassigned nodes
2017-05-10 09:12:46,329 INFO  [master:hadoop-master:60000] master.AssignmentManager: Clean cluster startup. Assigning user regions
2017-05-10 09:12:46,330 INFO  [master:hadoop-master:60000] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2017-05-10 09:12:46,334 INFO  [master:hadoop-master:60000] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-05-10 09:12:46,335 INFO  [master:hadoop-master:60000] master.AssignmentManager: Joined the cluster in 15ms, failover=false
2017-05-10 09:12:46,345 INFO  [master:hadoop-master:60000] master.TableNamespaceManager: Namespace table not found. Creating...
2017-05-10 09:12:46,498 DEBUG [master:hadoop-master:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:600000000000000
2017-05-10 09:12:46,501 WARN  [master:hadoop-master:60000] zookeeper.ZKTable: Moving table hbase:namespace state to enabling but was not first in disabled state: null
2017-05-10 09:12:46,532 INFO  [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] handler.CreateTableHandler: Create table hbase:namespace
2017-05-10 09:12:46,709 DEBUG [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://hadoop-master:9000/hbase/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-05-10 09:12:46,713 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = hdfs://hadoop-master:9000/hbase/.tmp Table name == hbase:namespace
2017-05-10 09:12:46,768 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Instantiated hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad.
2017-05-10 09:12:46,768 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closing hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad.: disabling compactions & flushes
2017-05-10 09:12:46,768 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad.
2017-05-10 09:12:46,768 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad.
2017-05-10 09:12:46,848 INFO  [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] catalog.MetaEditor: Added 1
2017-05-10 09:12:46,849 INFO  [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2017-05-10 09:12:46,850 DEBUG [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] master.AssignmentManager: Assigning 1 region(s) to hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:46,850 DEBUG [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: Timeout-on-RIT=151000
2017-05-10 09:12:46,853 DEBUG [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] zookeeper.ZKAssign: master:60000-0x5bf1a19f7c0000, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Async create of unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad with OFFLINE state
2017-05-10 09:12:46,900 DEBUG [main-EventThread] master.OfflineCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494407566848, server=null}, server=hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:46,901 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494407566848, server=null}, server=hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:46,904 INFO  [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] master.AssignmentManager: hadoop-slave2.hadoop,60020,1494407556979 unassigned znodes=1 of total=1
2017-05-10 09:12:46,904 INFO  [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494407566853, server=null} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494407566904, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:46,904 DEBUG [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] master.ServerManager: New admin connection to hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:46,988 DEBUG [hadoop-master,60000,1494407554046-GeneralBulkAssigner-2] master.AssignmentManager: Bulk assigning done for hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:46,988 DEBUG [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: bulk assigning total 1 regions to 3 servers, took 138ms, with 1 regions still in transition
2017-05-10 09:12:46,988 INFO  [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning done
2017-05-10 09:12:47,046 DEBUG [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/hbase:namespace/write-master:600000000000000
2017-05-10 09:12:47,046 INFO  [MASTER_TABLE_OPERATIONS-hadoop-master:60000-0] handler.CreateTableHandler: failed. null
2017-05-10 09:12:47,047 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-slave2.hadoop,60020,1494407556979, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494407566904, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:47,047 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494407566904, server=hadoop-slave2.hadoop,60020,1494407556979} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494407567047, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:47,296 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-slave2.hadoop,60020,1494407556979, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494407567047, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:47,296 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494407567047, server=hadoop-slave2.hadoop,60020,1494407556979} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494407567296, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:47,296 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of c9b8ca3abb5540b1eceabe95fa2a16ad from hadoop-slave2.hadoop,60020,1494407556979; deleting unassigned node
2017-05-10 09:12:47,312 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x5bf1a19f7c0000, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad in expected state RS_ZK_REGION_OPENED
2017-05-10 09:12:47,327 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad. deleted, state: {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494407567296, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-10 09:12:47,327 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined c9b8ca3abb5540b1eceabe95fa2a16ad on hadoop-slave2.hadoop,60020,1494407556979
2017-05-10 09:12:47,412 DEBUG [master:hadoop-master:60000] client.ClientSmallScanner: Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-10 09:12:47,530 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2017-05-10 09:12:47,580 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2017-05-10 09:12:47,580 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-05-10 09:12:47,621 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/default already exists and this is not a retry
2017-05-10 09:12:47,688 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/hbase already exists and this is not a retry
2017-05-10 09:12:47,721 INFO  [master:hadoop-master:60000] master.HMaster: Master has completed initialization
2017-05-10 09:12:47,721 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperWatcher: not a secure deployment, proceeding
2017-05-10 09:18:39,573 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x40783bcb] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x25bf1a19fb60000
2017-05-10 09:18:39,600 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x40783bcb] zookeeper.ZooKeeper: Session: 0x25bf1a19fb60000 closed
2017-05-10 09:18:39,600 INFO  [master:hadoop-master:60000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-10 10:23:40,345 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494407557387.1494407560938
2017-05-10 10:23:40,346 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494407560947
2017-05-10 10:23:40,346 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494407567273.meta
2017-05-10 10:23:40,346 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494407556979.1494407567461
2017-05-10 11:23:40,353 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494407557387.1494411161319
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494407565871.meta
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494407566835.meta
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494411162452
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494411167425.meta
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494407556979.1494407560936
2017-05-10 11:23:40,355 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494407556979.1494411167791
2017-05-10 12:23:33,848 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1674ms
No GCs detected
2017-05-10 12:23:40,359 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494407557387.1494414761467
2017-05-10 12:23:40,361 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494414762611
2017-05-10 12:23:40,361 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494414767541.meta
2017-05-10 12:23:40,361 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494407556979.1494414767943
Fri May 12 01:59:21 UTC 2017 Starting master on hadoop-master
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30718
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2017-05-12 01:59:22,477 INFO  [main] util.VersionInfo: HBase 0.98.24-hadoop2
2017-05-12 01:59:22,477 INFO  [main] util.VersionInfo: Source code repository git://buildbox/data/src/hbase revision=9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6
2017-05-12 01:59:22,477 INFO  [main] util.VersionInfo: Compiled by apurtell on Thu Dec 22 02:36:05 UTC 2016
2017-05-12 01:59:22,477 INFO  [main] util.VersionInfo: From source with checksum 286dfd46f04c92066a514339558c8bf2
2017-05-12 01:59:22,764 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2017-05-12 01:59:22,764 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2017-05-12 01:59:22,764 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
2017-05-12 01:59:22,764 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/root/hbase98/bin/../logs
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:LESSCLOSE=/usr/bin/lesspipe %s %s
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/root/hbase98/bin/../logs -Dhbase.log.file=hbase--master-hadoop-master.log -Dhbase.home.dir=/root/hbase98/bin/.. -Dhbase.id.str= -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/local/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/root/hbase98/bin/..
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HOSTNAME=hadoop-master
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:PWD=/root/hbase98/bin
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase--master.znode
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/local/hadoop
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/local/hadoop/lib/native
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2017-05-12 01:59:22,765 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2017-05-12 01:59:22,766 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-12 01:59:22,766 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
2017-05-12 01:59:22,766 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HOME=/root
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:LESSOPEN=| /usr/bin/lesspipe %s
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase--master.autorestart
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase--master-hadoop-master.log
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase--master-hadoop-master
2017-05-12 01:59:22,767 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=
2017-05-12 01:59:22,768 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.121-b00
2017-05-12 01:59:22,768 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/root/hbase98/bin/../logs, -Dhbase.log.file=hbase--master-hadoop-master.log, -Dhbase.home.dir=/root/hbase98/bin/.., -Dhbase.id.str=, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/local/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2017-05-12 01:59:22,959 DEBUG [main] master.HMaster: master/hadoop-master/172.18.0.2:60000 HConnection server-to-server retries=350
2017-05-12 01:59:23,566 INFO  [main] ipc.RpcServer: master/hadoop-master/172.18.0.2:60000: started 10 reader(s).
2017-05-12 01:59:25,688 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2017-05-12 01:59:25,800 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-05-12 01:59:25,800 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2017-05-12 01:59:32,287 INFO  [main] master.HMaster: hbase.rootdir=hdfs://hadoop-master:9000/hbase, hbase.cluster.distributed=true
2017-05-12 01:59:32,298 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-05-12 01:59:32,342 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=hadoop-master
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_121
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2017-05-12 01:59:32,347 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-77-generic
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2017-05-12 01:59:32,348 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/root/hbase98/bin
2017-05-12 01:59:32,349 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@15e426ac
2017-05-12 01:59:32,364 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 01:59:32,373 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-slave2.hadoop/172.18.0.4:2181, initiating session
2017-05-12 01:59:32,392 INFO  [main-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-slave2.hadoop/172.18.0.4:2181, sessionid = 0x25bfa61c0b00003, negotiated timeout = 90000
2017-05-12 01:59:32,574 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2017-05-12 01:59:32,574 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2017-05-12 01:59:32,642 INFO  [master:hadoop-master:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-05-12 01:59:32,673 INFO  [master:hadoop-master:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-05-12 01:59:32,675 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2017-05-12 01:59:32,675 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-12 01:59:32,684 INFO  [master:hadoop-master:60000] http.HttpServer: Jetty bound to port 60010
2017-05-12 01:59:32,684 INFO  [master:hadoop-master:60000] mortbay.log: jetty-6.1.26
2017-05-12 01:59:32,943 INFO  [master:hadoop-master:60000] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2017-05-12 01:59:33,050 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2017-05-12 01:59:33,053 INFO  [master:hadoop-master:60000] master.ActiveMasterManager: Registered Active Master=hadoop-master,60000,1494554366049
2017-05-12 01:59:33,058 INFO  [master:hadoop-master:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 01:59:36,624 INFO  [master:hadoop-master:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2017-05-12 01:59:36,700 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://hadoop-master:9000/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-05-12 01:59:36,823 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2017-05-12 01:59:37,359 INFO  [master:hadoop-master:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2017-05-12 01:59:37,370 DEBUG [master:hadoop-master:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2017-05-12 01:59:37,373 INFO  [master:hadoop-master:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-05-12 01:59:37,375 INFO  [master:hadoop-master:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2017-05-12 01:59:37,375 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Fetching table descriptors from the filesystem.
2017-05-12 01:59:37,465 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5069ae1d connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 01:59:37,465 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@d29d744
2017-05-12 01:59:37,466 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 01:59:37,467 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-slave1.hadoop/172.18.0.3:2181, initiating session
2017-05-12 01:59:37,499 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-slave1.hadoop/172.18.0.3:2181, sessionid = 0x15bfa61c0540000, negotiated timeout = 90000
2017-05-12 01:59:37,516 DEBUG [master:hadoop-master:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7a399295
2017-05-12 01:59:37,598 INFO  [master:hadoop-master:60000] master.HMaster: Server active/primary master=hadoop-master,60000,1494554366049, sessionid=0x25bfa61c0b00003, setting cluster-up flag (Was=false)
2017-05-12 01:59:37,781 INFO  [master:hadoop-master:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-05-12 01:59:37,783 DEBUG [master:hadoop-master:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:hadoop-master,60000,1494554366049
2017-05-12 01:59:37,822 INFO  [master:hadoop-master:60000] master.MasterCoprocessorHost: System coprocessor loading is enabled
2017-05-12 01:59:37,837 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 01:59:37,837 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 01:59:37,837 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 01:59:37,837 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 01:59:37,838 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-hadoop-master:60000, corePoolSize=10, maxPoolSize=10
2017-05-12 01:59:37,838 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-hadoop-master:60000, corePoolSize=1, maxPoolSize=1
2017-05-12 01:59:37,840 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-05-12 01:59:37,841 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 01:59:37,841 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@59d0ad97
2017-05-12 01:59:37,846 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave2.hadoop/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 01:59:37,846 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-slave2.hadoop/172.18.0.4:2181, initiating session
2017-05-12 01:59:37,872 INFO  [master:hadoop-master:60000-SendThread(hadoop-slave2.hadoop:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-slave2.hadoop/172.18.0.4:2181, sessionid = 0x25bfa61c0b00005, negotiated timeout = 90000
2017-05-12 01:59:37,979 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-05-12 01:59:37,981 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-05-12 01:59:37,982 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-05-12 01:59:37,983 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-05-12 01:59:37,983 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-05-12 01:59:37,983 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 01:59:38,326 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=hadoop-master,60020,1494554366347
2017-05-12 01:59:38,326 INFO  [FifoRpcScheduler.handler1-thread-3] master.ServerManager: Registering server=hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 01:59:38,326 INFO  [FifoRpcScheduler.handler1-thread-2] master.ServerManager: Registering server=hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:38,329 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 01:59:38,329 INFO  [FifoRpcScheduler.handler1-thread-3] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 01:59:38,334 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 351 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 01:59:38,379 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:38,380 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 01:59:38,381 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-master,60020,1494554366347
2017-05-12 01:59:39,844 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1861 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 01:59:41,347 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 3364 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 01:59:42,499 INFO  [master:hadoop-master:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4516 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-05-12 01:59:42,503 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387 doesn't belong to a known region server, splitting
2017-05-12 01:59:42,503 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347 belongs to an existing region server
2017-05-12 01:59:42,503 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923 doesn't belong to a known region server, splitting
2017-05-12 01:59:42,503 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239 belongs to an existing region server
2017-05-12 01:59:42,503 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979 doesn't belong to a known region server, splitting
2017-05-12 01:59:42,504 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224 belongs to an existing region server
2017-05-12 01:59:43,315 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2017-05-12 01:59:43,338 DEBUG [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2017-05-12 01:59:43,340 DEBUG [master:hadoop-master:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=hadoop-slave2.hadoop,60020,1494554366224; 3 (online=3, available=3) available servers, forceNewPlan=false
2017-05-12 01:59:43,341 INFO  [master:hadoop-master:60000] master.AssignmentManager: Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-12 01:59:43,341 DEBUG [master:hadoop-master:60000] zookeeper.ZKAssign: master:60000-0x25bfa61c0b00003, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-05-12 01:59:43,364 DEBUG [master:hadoop-master:60000] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2017-05-12 01:59:43,414 INFO  [master:hadoop-master:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:43,414 INFO  [master:hadoop-master:60000] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1494554383341, server=null} to {1588230740 state=PENDING_OPEN, ts=1494554383414, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:43,414 DEBUG [master:hadoop-master:60000] master.ServerManager: New admin connection to hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:43,487 INFO  [master:hadoop-master:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2017-05-12 01:59:43,519 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-slave2.hadoop,60020,1494554366224, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1494554383414, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:43,520 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1494554383414, server=hadoop-slave2.hadoop,60020,1494554366224} to {1588230740 state=OPENING, ts=1494554383520, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:44,005 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-slave2.hadoop,60020,1494554366224, region=1588230740, current_state={1588230740 state=OPENING, ts=1494554383520, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:44,005 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1494554383520, server=hadoop-slave2.hadoop,60020,1494554366224} to {1588230740 state=OPEN, ts=1494554384005, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:44,007 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from hadoop-slave2.hadoop,60020,1494554366224; deleting unassigned node
2017-05-12 01:59:44,021 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x25bfa61c0b00003, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-05-12 01:59:44,022 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1494554384005, server=hadoop-slave2.hadoop,60020,1494554366224}
2017-05-12 01:59:44,022 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:44,023 INFO  [master:hadoop-master:60000] master.HMaster: hbase:meta assigned=1, rit=false, location=hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:44,089 INFO  [master:hadoop-master:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2017-05-12 01:59:44,109 INFO  [master:hadoop-master:60000] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494554384109, server=hadoop-slave2.hadoop,60020,1494407556979} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494554384109, server=hadoop-slave2.hadoop,60020,1494407556979}
2017-05-12 01:59:44,110 INFO  [master:hadoop-master:60000] master.RegionStates: Offlined c9b8ca3abb5540b1eceabe95fa2a16ad from hadoop-slave2.hadoop,60020,1494407556979
2017-05-12 01:59:44,157 DEBUG [master:hadoop-master:60000] master.AssignmentManager: Found queued dead server hadoop-slave2.hadoop,60020,1494407556979
2017-05-12 01:59:44,157 INFO  [master:hadoop-master:60000] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2017-05-12 01:59:44,163 INFO  [master:hadoop-master:60000] master.AssignmentManager: Joined the cluster in 74ms, failover=true
2017-05-12 01:59:44,167 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Splitting logs for hadoop-master,60020,1494407557387 before assignment; region count=0
2017-05-12 01:59:44,175 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Splitting logs for hadoop-slave2.hadoop,60020,1494407556979 before assignment; region count=1
2017-05-12 01:59:44,175 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Splitting logs for hadoop-slave1.hadoop,60020,1494407556923 before assignment; region count=0
2017-05-12 01:59:44,223 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387-splitting
2017-05-12 01:59:44,224 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: dead splitlog workers [hadoop-master,60020,1494407557387]
2017-05-12 01:59:44,237 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979-splitting
2017-05-12 01:59:44,237 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: dead splitlog workers [hadoop-slave2.hadoop,60020,1494407556979]
2017-05-12 01:59:44,247 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 01:59:44,247 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387-splitting]
2017-05-12 01:59:44,262 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting
2017-05-12 01:59:44,262 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: dead splitlog workers [hadoop-slave1.hadoop,60020,1494407556923]
2017-05-12 01:59:44,263 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 01:59:44,263 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979-splitting]
2017-05-12 01:59:44,264 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 01:59:44,265 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting]
2017-05-12 01:59:44,282 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637
2017-05-12 01:59:44,296 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111
2017-05-12 01:59:44,297 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750
2017-05-12 01:59:44,299 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637 ver = 0
2017-05-12 01:59:44,299 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111 ver = 0
2017-05-12 01:59:44,299 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750 ver = 0
2017-05-12 01:59:44,348 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637 acquired by hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 01:59:44,348 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111 acquired by hadoop-master,60020,1494554366347
2017-05-12 01:59:44,375 INFO  [hadoop-master,60000,1494554366049.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 3 unassigned = 1 tasks={/hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637=last_update = 1494554384348 last_version = 1 cur_worker_name = hadoop-slave1.hadoop,60020,1494554366239 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111=last_update = 1494554384348 last_version = 1 cur_worker_name = hadoop-master,60020,1494554366347 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2017-05-12 01:59:44,380 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750 acquired by hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:48,638 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750 entered state: DONE hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 01:59:48,729 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting/hadoop-slave1.hadoop%2C60020%2C1494407556923.1494418362750 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-slave1.hadoop%2C60020%2C1494407556923.1494418362750
2017-05-12 01:59:48,730 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750
2017-05-12 01:59:48,739 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494407556923-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494407556923.1494418362750
2017-05-12 01:59:48,739 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637 entered state: DONE hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 01:59:48,820 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387-splitting/hadoop-master%2C60020%2C1494407557387.1494418361637 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-master%2C60020%2C1494407557387.1494418361637
2017-05-12 01:59:48,822 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637
2017-05-12 01:59:48,822 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111 entered state: DONE hadoop-master,60020,1494554366347
2017-05-12 01:59:48,863 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494407557387-splitting] in 4616ms
2017-05-12 01:59:48,864 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.RegionStates: Adding to processed servers hadoop-master,60020,1494407557387
2017-05-12 01:59:48,864 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Reassigning 0 region(s) that hadoop-master,60020,1494407557387 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 01:59:48,864 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.DeadServer: Finished processing hadoop-master,60020,1494407557387
2017-05-12 01:59:48,864 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-master,60020,1494407557387
2017-05-12 01:59:48,895 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979-splitting/hadoop-slave2.hadoop%2C60020%2C1494407556979.1494418368111 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-slave2.hadoop%2C60020%2C1494407556979.1494418368111
2017-05-12 01:59:48,896 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111
2017-05-12 01:59:48,896 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494407557387-splitting%2Fhadoop-master%252C60020%252C1494407557387.1494418361637
2017-05-12 01:59:48,930 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494407556979-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494407556979.1494418368111
2017-05-12 01:59:48,937 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494407556979-splitting] in 4674ms
2017-05-12 01:59:48,937 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.RegionStates: Adding to processed servers hadoop-slave2.hadoop,60020,1494407556979
2017-05-12 01:59:48,937 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Reassigning 1 region(s) that hadoop-slave2.hadoop,60020,1494407556979 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 01:59:48,937 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2017-05-12 01:59:48,939 DEBUG [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to hadoop-master,60020,1494554366347
2017-05-12 01:59:48,939 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: Timeout-on-RIT=151000
2017-05-12 01:59:48,940 DEBUG [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x25bfa61c0b00003, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Async create of unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad with OFFLINE state
2017-05-12 01:59:48,980 DEBUG [main-EventThread] master.OfflineCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494554384109, server=hadoop-slave2.hadoop,60020,1494407556979}, server=hadoop-master,60020,1494554366347
2017-05-12 01:59:48,981 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494554384109, server=hadoop-slave2.hadoop,60020,1494407556979}, server=hadoop-master,60020,1494554366347
2017-05-12 01:59:48,981 INFO  [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] master.AssignmentManager: hadoop-master,60020,1494554366347 unassigned znodes=1 of total=1
2017-05-12 01:59:48,981 INFO  [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494554388940, server=hadoop-slave2.hadoop,60020,1494407556979} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494554388981, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:48,981 DEBUG [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] master.ServerManager: New admin connection to hadoop-master,60020,1494554366347
2017-05-12 01:59:49,002 WARN  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting
2017-05-12 01:59:49,002 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting] in 4737ms
2017-05-12 01:59:49,002 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.RegionStates: Adding to processed servers hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 01:59:49,002 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Reassigning 0 region(s) that hadoop-slave1.hadoop,60020,1494407556923 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 01:59:49,002 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.DeadServer: Finished processing hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 01:59:49,003 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 01:59:49,032 DEBUG [hadoop-master,60000,1494554366049-GeneralBulkAssigner-0] master.AssignmentManager: Bulk assigning done for hadoop-master,60020,1494554366347
2017-05-12 01:59:49,032 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: bulk assigning total 1 regions to 3 servers, took 93ms, with 1 regions still in transition
2017-05-12 01:59:49,032 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning done
2017-05-12 01:59:49,032 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.DeadServer: Finished processing hadoop-slave2.hadoop,60020,1494407556979
2017-05-12 01:59:49,032 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-slave2.hadoop,60020,1494407556979
2017-05-12 01:59:49,065 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-master,60020,1494554366347, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494554388981, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:49,065 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494554388981, server=hadoop-master,60020,1494554366347} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494554389065, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:49,356 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-master,60020,1494554366347, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494554389065, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:49,356 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494554389065, server=hadoop-master,60020,1494554366347} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494554389356, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:49,356 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of c9b8ca3abb5540b1eceabe95fa2a16ad from hadoop-master,60020,1494554366347; deleting unassigned node
2017-05-12 01:59:49,381 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x25bfa61c0b00003, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad in expected state RS_ZK_REGION_OPENED
2017-05-12 01:59:49,398 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad. deleted, state: {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494554389356, server=hadoop-master,60020,1494554366347}
2017-05-12 01:59:49,399 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined c9b8ca3abb5540b1eceabe95fa2a16ad on hadoop-master,60020,1494554366347
2017-05-12 01:59:49,565 DEBUG [master:hadoop-master:60000] client.ClientSmallScanner: Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-12 01:59:49,821 INFO  [master:hadoop-master:60000] master.HMaster: Master has completed initialization
2017-05-12 01:59:49,821 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperWatcher: not a secure deployment, proceeding
2017-05-12 01:59:49,822 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2017-05-12 01:59:49,822 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-05-12 02:05:37,461 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x15bfa61c0540000
2017-05-12 02:05:37,489 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] zookeeper.ZooKeeper: Session: 0x15bfa61c0540000 closed
2017-05-12 02:05:37,489 INFO  [master:hadoop-master:60000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-12 02:10:37,990 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494407557387.1494418361637
2017-05-12 02:10:37,991 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494407556923.1494418362750
2017-05-12 02:10:37,991 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494407556979.1494418368111
2017-05-12 03:10:37,996 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494554366347.1494554378697
2017-05-12 03:10:37,997 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494554366239.1494554378683
2017-05-12 03:10:37,997 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494554378691
2017-05-12 03:10:37,997 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494554389319.meta
2017-05-12 04:10:38,003 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494554366347.1494557980233
2017-05-12 04:10:38,004 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494554366239.1494557980238
2017-05-12 04:10:38,004 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494554383517.meta
2017-05-12 04:10:38,004 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494557980239
2017-05-12 04:10:38,004 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494557989559.meta
2017-05-12 05:10:38,007 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494554366347.1494561580430
2017-05-12 05:10:38,008 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494554366239.1494561580437
2017-05-12 05:10:38,008 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494561580437
2017-05-12 05:10:38,008 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494561589651.meta
2017-05-12 05:39:45,007 INFO  [1320251536@qtp-2122048011-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5069ae1d connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 05:39:45,008 INFO  [1320251536@qtp-2122048011-2] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@a2b7b61
2017-05-12 05:39:45,017 INFO  [1320251536@qtp-2122048011-2-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 05:39:45,017 INFO  [1320251536@qtp-2122048011-2-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-12 05:39:45,165 INFO  [1320251536@qtp-2122048011-2-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bfa61c07f0002, negotiated timeout = 90000
2017-05-12 05:45:37,483 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x5bfa61c07f0002
2017-05-12 05:45:37,500 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] zookeeper.ZooKeeper: Session: 0x5bfa61c07f0002 closed
2017-05-12 05:45:37,500 INFO  [1320251536@qtp-2122048011-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-12 05:45:37,500 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2017-05-12 05:51:57,840 INFO  [1139657975@qtp-2122048011-5] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5069ae1d connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 05:51:57,840 INFO  [1139657975@qtp-2122048011-5] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@192e3bbf
2017-05-12 05:51:57,841 INFO  [1139657975@qtp-2122048011-5-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 05:51:57,842 INFO  [1139657975@qtp-2122048011-5-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-12 05:51:57,867 INFO  [1139657975@qtp-2122048011-5-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bfa61c07f0003, negotiated timeout = 90000
2017-05-12 05:57:37,484 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x5bfa61c07f0003
2017-05-12 05:57:37,510 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] zookeeper.ZooKeeper: Session: 0x5bfa61c07f0003 closed
2017-05-12 05:57:37,510 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2017-05-12 05:57:37,510 INFO  [1139657975@qtp-2122048011-5-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-12 05:58:11,258 INFO  [2051981803@qtp-2122048011-9] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5069ae1d connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 05:58:11,258 INFO  [2051981803@qtp-2122048011-9] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@12b5ba0d
2017-05-12 05:58:11,259 INFO  [2051981803@qtp-2122048011-9-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 05:58:11,260 INFO  [2051981803@qtp-2122048011-9-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-12 05:58:11,285 INFO  [2051981803@qtp-2122048011-9-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bfa61c07f0004, negotiated timeout = 90000
2017-05-12 05:58:38,920 INFO  [1006456816@qtp-2122048011-12] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 06:03:37,485 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x5bfa61c07f0004
2017-05-12 06:03:37,511 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] zookeeper.ZooKeeper: Session: 0x5bfa61c07f0004 closed
2017-05-12 06:03:37,511 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x5069ae1d] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2017-05-12 06:03:37,511 INFO  [2051981803@qtp-2122048011-9-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-12 06:10:38,024 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494554366347.1494565180565
2017-05-12 06:10:38,025 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494554366239.1494565180575
2017-05-12 06:10:38,025 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494565180582
2017-05-12 06:10:38,025 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494565189755.meta
Fri May 12 06:23:00 UTC 2017 Starting master on hadoop-master
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30718
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1048576
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) unlimited
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2017-05-12 06:23:01,629 INFO  [main] util.VersionInfo: HBase 0.98.24-hadoop2
2017-05-12 06:23:01,629 INFO  [main] util.VersionInfo: Source code repository git://buildbox/data/src/hbase revision=9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6
2017-05-12 06:23:01,629 INFO  [main] util.VersionInfo: Compiled by apurtell on Thu Dec 22 02:36:05 UTC 2016
2017-05-12 06:23:01,629 INFO  [main] util.VersionInfo: From source with checksum 286dfd46f04c92066a514339558c8bf2
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/root/hbase98/bin/../logs
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:LESSCLOSE=/usr/bin/lesspipe %s %s
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/root/hbase98/bin/../logs -Dhbase.log.file=hbase--master-hadoop-master.log -Dhbase.home.dir=/root/hbase98/bin/.. -Dhbase.id.str= -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/local/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/root/hbase98/bin/..
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HOSTNAME=hadoop-master
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:PWD=/root/hbase98/bin
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase--master.znode
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/local/hadoop
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/local/hadoop/lib/native
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2017-05-12 06:23:01,905 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2017-05-12 06:23:01,906 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:HOME=/root
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:LESSOPEN=| /usr/bin/lesspipe %s
2017-05-12 06:23:01,907 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase--master.autorestart
2017-05-12 06:23:01,908 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:
2017-05-12 06:23:01,908 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase--master-hadoop-master.log
2017-05-12 06:23:01,909 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase--master-hadoop-master
2017-05-12 06:23:01,909 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=
2017-05-12 06:23:01,910 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.121-b00
2017-05-12 06:23:01,911 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/root/hbase98/bin/../logs, -Dhbase.log.file=hbase--master-hadoop-master.log, -Dhbase.home.dir=/root/hbase98/bin/.., -Dhbase.id.str=, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/local/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2017-05-12 06:23:02,172 DEBUG [main] master.HMaster: master/hadoop-master/172.18.0.2:60000 HConnection server-to-server retries=350
2017-05-12 06:23:02,535 INFO  [main] ipc.RpcServer: master/hadoop-master/172.18.0.2:60000: started 10 reader(s).
2017-05-12 06:23:02,860 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2017-05-12 06:23:03,004 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-05-12 06:23:03,004 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2017-05-12 06:23:05,409 INFO  [main] master.HMaster: hbase.rootdir=hdfs://hadoop-master:9000/hbase, hbase.cluster.distributed=true
2017-05-12 06:23:05,413 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-05-12 06:23:05,467 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=hadoop-master
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_121
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2017-05-12 06:23:05,480 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/root/hbase98/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/root/hbase98/bin/..:/root/hbase98/bin/../lib/activation-1.1.jar:/root/hbase98/bin/../lib/aopalliance-1.0.jar:/root/hbase98/bin/../lib/asm-3.1.jar:/root/hbase98/bin/../lib/avro-1.7.4.jar:/root/hbase98/bin/../lib/commons-beanutils-1.7.0.jar:/root/hbase98/bin/../lib/commons-beanutils-core-1.8.0.jar:/root/hbase98/bin/../lib/commons-cli-1.2.jar:/root/hbase98/bin/../lib/commons-codec-1.7.jar:/root/hbase98/bin/../lib/commons-collections-3.2.2.jar:/root/hbase98/bin/../lib/commons-compress-1.4.1.jar:/root/hbase98/bin/../lib/commons-configuration-1.6.jar:/root/hbase98/bin/../lib/commons-daemon-1.0.13.jar:/root/hbase98/bin/../lib/commons-digester-1.8.jar:/root/hbase98/bin/../lib/commons-el-1.0.jar:/root/hbase98/bin/../lib/commons-httpclient-3.1.jar:/root/hbase98/bin/../lib/commons-io-2.4.jar:/root/hbase98/bin/../lib/commons-lang-2.6.jar:/root/hbase98/bin/../lib/commons-logging-1.1.1.jar:/root/hbase98/bin/../lib/commons-math-2.1.jar:/root/hbase98/bin/../lib/commons-net-3.1.jar:/root/hbase98/bin/../lib/findbugs-annotations-1.3.9-1.jar:/root/hbase98/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/root/hbase98/bin/../lib/grizzly-framework-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-server-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-http-servlet-2.1.2.jar:/root/hbase98/bin/../lib/grizzly-rcm-2.1.2.jar:/root/hbase98/bin/../lib/guava-12.0.1.jar:/root/hbase98/bin/../lib/guice-3.0.jar:/root/hbase98/bin/../lib/guice-servlet-3.0.jar:/root/hbase98/bin/../lib/hadoop-annotations-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-auth-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-hdfs-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-api-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-client-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/root/hbase98/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/root/hbase98/bin/../lib/hamcrest-core-1.3.jar:/root/hbase98/bin/../lib/hbase-annotations-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-checkstyle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-client-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-common-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-examples-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-hadoop2-compat-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-it-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-prefix-tree-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-protocol-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-resource-bundle-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-rest-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2-tests.jar:/root/hbase98/bin/../lib/hbase-server-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-shell-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-testing-util-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/hbase-thrift-0.98.24-hadoop2.jar:/root/hbase98/bin/../lib/high-scale-lib-1.1.1.jar:/root/hbase98/bin/../lib/htrace-core-2.04.jar:/root/hbase98/bin/../lib/httpclient-4.1.3.jar:/root/hbase98/bin/../lib/httpcore-4.1.3.jar:/root/hbase98/bin/../lib/jackson-core-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-jaxrs-1.8.8.jar:/root/hbase98/bin/../lib/jackson-mapper-asl-1.8.8.jar:/root/hbase98/bin/../lib/jackson-xc-1.8.8.jar:/root/hbase98/bin/../lib/jamon-runtime-2.4.1.jar:/root/hbase98/bin/../lib/jasper-compiler-5.5.23.jar:/root/hbase98/bin/../lib/jasper-runtime-5.5.23.jar:/root/hbase98/bin/../lib/javax.inject-1.jar:/root/hbase98/bin/../lib/javax.servlet-3.1.jar:/root/hbase98/bin/../lib/javax.servlet-api-3.0.1.jar:/root/hbase98/bin/../lib/jaxb-api-2.2.2.jar:/root/hbase98/bin/../lib/jaxb-impl-2.2.3-1.jar:/root/hbase98/bin/../lib/jcodings-1.0.8.jar:/root/hbase98/bin/../lib/jersey-client-1.8.jar:/root/hbase98/bin/../lib/jersey-core-1.8.jar:/root/hbase98/bin/../lib/jersey-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jersey-guice-1.9.jar:/root/hbase98/bin/../lib/jersey-json-1.8.jar:/root/hbase98/bin/../lib/jersey-server-1.8.jar:/root/hbase98/bin/../lib/jersey-test-framework-core-1.9.jar:/root/hbase98/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/root/hbase98/bin/../lib/jets3t-0.6.1.jar:/root/hbase98/bin/../lib/jettison-1.3.1.jar:/root/hbase98/bin/../lib/jetty-6.1.26.jar:/root/hbase98/bin/../lib/jetty-sslengine-6.1.26.jar:/root/hbase98/bin/../lib/jetty-util-6.1.26.jar:/root/hbase98/bin/../lib/joni-2.1.2.jar:/root/hbase98/bin/../lib/jruby-complete-1.6.8.jar:/root/hbase98/bin/../lib/jsch-0.1.42.jar:/root/hbase98/bin/../lib/jsp-2.1-6.1.14.jar:/root/hbase98/bin/../lib/jsp-api-2.1-6.1.14.jar:/root/hbase98/bin/../lib/junit-4.11.jar:/root/hbase98/bin/../lib/libthrift-0.9.0.jar:/root/hbase98/bin/../lib/log4j-1.2.17.jar:/root/hbase98/bin/../lib/management-api-3.0.0-b012.jar:/root/hbase98/bin/../lib/metrics-core-2.2.0.jar:/root/hbase98/bin/../lib/netty-3.6.6.Final.jar:/root/hbase98/bin/../lib/paranamer-2.3.jar:/root/hbase98/bin/../lib/protobuf-java-2.5.0.jar:/root/hbase98/bin/../lib/servlet-api-2.5-6.1.14.jar:/root/hbase98/bin/../lib/slf4j-api-1.6.4.jar:/root/hbase98/bin/../lib/slf4j-log4j12-1.6.4.jar:/root/hbase98/bin/../lib/snappy-java-1.0.4.1.jar:/root/hbase98/bin/../lib/xmlenc-0.52.jar:/root/hbase98/bin/../lib/xz-1.0.jar:/root/hbase98/bin/../lib/zookeeper-3.4.6.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop/lib/native
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-77-generic
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2017-05-12 06:23:05,481 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/root/hbase98/bin
2017-05-12 06:23:05,482 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@553ca484
2017-05-12 06:23:05,516 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-slave1.hadoop/172.18.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 06:23:05,527 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-slave1.hadoop/172.18.0.3:2181, initiating session
2017-05-12 06:23:05,558 INFO  [main-SendThread(hadoop-slave1.hadoop:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-slave1.hadoop/172.18.0.3:2181, sessionid = 0x15bfb5322060001, negotiated timeout = 90000
2017-05-12 06:23:05,706 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2017-05-12 06:23:05,706 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2017-05-12 06:23:05,770 INFO  [master:hadoop-master:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-05-12 06:23:05,804 INFO  [master:hadoop-master:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-05-12 06:23:05,806 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2017-05-12 06:23:05,806 INFO  [master:hadoop-master:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-12 06:23:05,813 INFO  [master:hadoop-master:60000] http.HttpServer: Jetty bound to port 60010
2017-05-12 06:23:05,813 INFO  [master:hadoop-master:60000] mortbay.log: jetty-6.1.26
2017-05-12 06:23:06,074 INFO  [master:hadoop-master:60000] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2017-05-12 06:23:06,179 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2017-05-12 06:23:06,180 INFO  [master:hadoop-master:60000] master.ActiveMasterManager: Registered Active Master=hadoop-master,60000,1494570183603
2017-05-12 06:23:06,187 INFO  [master:hadoop-master:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 06:23:06,503 INFO  [master:hadoop-master:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2017-05-12 06:23:06,586 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://hadoop-master:9000/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-05-12 06:23:06,641 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2017-05-12 06:23:06,715 INFO  [master:hadoop-master:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2017-05-12 06:23:06,720 DEBUG [master:hadoop-master:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2017-05-12 06:23:06,725 INFO  [master:hadoop-master:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-05-12 06:23:06,726 INFO  [master:hadoop-master:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2017-05-12 06:23:06,727 DEBUG [master:hadoop-master:60000] util.FSTableDescriptors: Fetching table descriptors from the filesystem.
2017-05-12 06:23:06,776 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6a7438e8 connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 06:23:06,776 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@3e0db8d8
2017-05-12 06:23:06,777 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 06:23:06,777 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-12 06:23:06,786 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bfb5322300001, negotiated timeout = 90000
2017-05-12 06:23:06,797 DEBUG [master:hadoop-master:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3eac3b6
2017-05-12 06:23:06,868 INFO  [master:hadoop-master:60000] master.HMaster: Server active/primary master=hadoop-master,60000,1494570183603, sessionid=0x15bfb5322060001, setting cluster-up flag (Was=false)
2017-05-12 06:23:06,990 INFO  [master:hadoop-master:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-05-12 06:23:06,999 DEBUG [master:hadoop-master:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:hadoop-master,60000,1494570183603
2017-05-12 06:23:07,023 INFO  [master:hadoop-master:60000] master.MasterCoprocessorHost: System coprocessor loading is enabled
2017-05-12 06:23:07,029 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 06:23:07,029 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 06:23:07,029 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 06:23:07,029 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-hadoop-master:60000, corePoolSize=5, maxPoolSize=5
2017-05-12 06:23:07,030 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-hadoop-master:60000, corePoolSize=10, maxPoolSize=10
2017-05-12 06:23:07,030 DEBUG [master:hadoop-master:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-hadoop-master:60000, corePoolSize=1, maxPoolSize=1
2017-05-12 06:23:07,031 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-05-12 06:23:07,033 INFO  [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181
2017-05-12 06:23:07,033 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@52158e1a
2017-05-12 06:23:07,033 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server hadoop-master/172.18.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2017-05-12 06:23:07,033 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Socket connection established to hadoop-master/172.18.0.2:2181, initiating session
2017-05-12 06:23:07,053 INFO  [master:hadoop-master:60000-SendThread(hadoop-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server hadoop-master/172.18.0.2:2181, sessionid = 0x5bfb5322300005, negotiated timeout = 90000
2017-05-12 06:23:07,120 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-05-12 06:23:07,125 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-05-12 06:23:07,126 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-05-12 06:23:07,131 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-05-12 06:23:07,132 DEBUG [master:hadoop-master:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-05-12 06:23:07,132 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 06:23:07,506 INFO  [FifoRpcScheduler.handler1-thread-3] master.ServerManager: Registering server=hadoop-master,60020,1494570184588
2017-05-12 06:23:07,506 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:07,506 INFO  [FifoRpcScheduler.handler1-thread-2] master.ServerManager: Registering server=hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:07,509 INFO  [FifoRpcScheduler.handler1-thread-3] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 06:23:07,509 INFO  [FifoRpcScheduler.handler1-thread-2] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 06:23:07,509 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2017-05-12 06:23:07,539 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 407 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 06:23:07,551 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:07,552 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:07,558 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-master,60020,1494570184588
2017-05-12 06:23:07,563 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:07,563 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:09,050 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1918 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 06:23:10,553 INFO  [master:hadoop-master:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 3421 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-05-12 06:23:11,655 INFO  [master:hadoop-master:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4523 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347 doesn't belong to a known region server, splitting
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494570184588 belongs to an existing region server
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting doesn't belong to a known region server, splitting
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239 doesn't belong to a known region server, splitting
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494570183952 belongs to an existing region server
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224 doesn't belong to a known region server, splitting
2017-05-12 06:23:11,659 INFO  [master:hadoop-master:60000] master.MasterFileSystem: Log folder hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494570183776 belongs to an existing region server
2017-05-12 06:23:12,470 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2017-05-12 06:23:12,494 DEBUG [master:hadoop-master:60000] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2017-05-12 06:23:12,497 DEBUG [master:hadoop-master:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=hadoop-slave1.hadoop,60020,1494570183952; 3 (online=3, available=3) available servers, forceNewPlan=false
2017-05-12 06:23:12,497 INFO  [master:hadoop-master:60000] master.AssignmentManager: Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-12 06:23:12,497 DEBUG [master:hadoop-master:60000] zookeeper.ZKAssign: master:60000-0x15bfb5322060001, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-05-12 06:23:12,520 DEBUG [master:hadoop-master:60000] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2017-05-12 06:23:12,561 INFO  [master:hadoop-master:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:12,562 INFO  [master:hadoop-master:60000] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1494570192497, server=null} to {1588230740 state=PENDING_OPEN, ts=1494570192562, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:12,562 DEBUG [master:hadoop-master:60000] master.ServerManager: New admin connection to hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:12,633 INFO  [master:hadoop-master:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2017-05-12 06:23:12,662 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-slave1.hadoop,60020,1494570183952, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1494570192562, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:12,667 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1494570192562, server=hadoop-slave1.hadoop,60020,1494570183952} to {1588230740 state=OPENING, ts=1494570192667, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:13,059 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-slave1.hadoop,60020,1494570183952, region=1588230740, current_state={1588230740 state=OPENING, ts=1494570192667, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:13,060 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1494570192667, server=hadoop-slave1.hadoop,60020,1494570183952} to {1588230740 state=OPEN, ts=1494570193060, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:13,061 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from hadoop-slave1.hadoop,60020,1494570183952; deleting unassigned node
2017-05-12 06:23:13,078 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x15bfb5322060001, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-05-12 06:23:13,087 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1494570193060, server=hadoop-slave1.hadoop,60020,1494570183952}
2017-05-12 06:23:13,087 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:13,088 INFO  [master:hadoop-master:60000] master.HMaster: hbase:meta assigned=1, rit=false, location=hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:13,163 INFO  [master:hadoop-master:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2017-05-12 06:23:13,184 INFO  [master:hadoop-master:60000] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494570193184, server=hadoop-master,60020,1494554366347} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494570193184, server=hadoop-master,60020,1494554366347}
2017-05-12 06:23:13,185 INFO  [master:hadoop-master:60000] master.RegionStates: Offlined c9b8ca3abb5540b1eceabe95fa2a16ad from hadoop-master,60020,1494554366347
2017-05-12 06:23:13,230 DEBUG [master:hadoop-master:60000] master.AssignmentManager: Found queued dead server hadoop-master,60020,1494554366347
2017-05-12 06:23:13,230 INFO  [master:hadoop-master:60000] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2017-05-12 06:23:13,256 INFO  [master:hadoop-master:60000] master.AssignmentManager: Joined the cluster in 93ms, failover=true
2017-05-12 06:23:13,257 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Splitting logs for hadoop-master,60020,1494554366347 before assignment; region count=1
2017-05-12 06:23:13,260 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] handler.ServerShutdownHandler: Splitting logs for hadoop-slave1.hadoop,60020,1494554366239 before assignment; region count=0
2017-05-12 06:23:13,260 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Splitting logs for hadoop-slave1.hadoop,60020,1494407556923 before assignment; region count=0
2017-05-12 06:23:13,265 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Splitting logs for hadoop-slave2.hadoop,60020,1494554366224 before assignment; region count=0
2017-05-12 06:23:13,302 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347-splitting
2017-05-12 06:23:13,303 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: dead splitlog workers [hadoop-master,60020,1494554366347]
2017-05-12 06:23:13,313 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 06:23:13,314 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347-splitting]
2017-05-12 06:23:13,318 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239-splitting
2017-05-12 06:23:13,319 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.SplitLogManager: dead splitlog workers [hadoop-slave1.hadoop,60020,1494554366239]
2017-05-12 06:23:13,325 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: dead splitlog workers [hadoop-slave1.hadoop,60020,1494407556923]
2017-05-12 06:23:13,328 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting is empty dir, no logs to split
2017-05-12 06:23:13,328 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 06:23:13,328 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: started splitting 0 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting]
2017-05-12 06:23:13,335 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.MasterFileSystem: Renamed region directory: hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224-splitting
2017-05-12 06:23:13,335 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: dead splitlog workers [hadoop-slave2.hadoop,60020,1494554366224]
2017-05-12 06:23:13,336 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 06:23:13,336 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239-splitting]
2017-05-12 06:23:13,342 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: Scheduling batch of logs to split
2017-05-12 06:23:13,342 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: started splitting 1 logs in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224-splitting]
2017-05-12 06:23:13,342 WARN  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting
2017-05-12 06:23:13,342 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494407556923-splitting] in 14ms
2017-05-12 06:23:13,343 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.RegionStates: Adding to processed servers hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 06:23:13,343 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Reassigning 0 region(s) that hadoop-slave1.hadoop,60020,1494407556923 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 06:23:13,343 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] master.DeadServer: Finished processing hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 06:23:13,343 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-1] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-slave1.hadoop,60020,1494407556923
2017-05-12 06:23:13,347 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683
2017-05-12 06:23:13,357 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692
2017-05-12 06:23:13,357 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717
2017-05-12 06:23:13,358 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683 ver = 0
2017-05-12 06:23:13,358 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692 ver = 0
2017-05-12 06:23:13,358 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717 ver = 0
2017-05-12 06:23:13,378 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683 acquired by hadoop-master,60020,1494570184588
2017-05-12 06:23:13,380 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717 acquired by hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:13,407 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692 acquired by hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:13,727 INFO  [hadoop-master,60000,1494570183603.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 3 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692=last_update = 1494570193464 last_version = 2 cur_worker_name = hadoop-slave1.hadoop,60020,1494570183952 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717=last_update = 1494570193448 last_version = 2 cur_worker_name = hadoop-slave2.hadoop,60020,1494570183776 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683=last_update = 1494570193464 last_version = 2 cur_worker_name = hadoop-master,60020,1494570184588 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2017-05-12 06:23:17,618 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692 entered state: DONE hadoop-slave1.hadoop,60020,1494570183952
2017-05-12 06:23:17,643 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239-splitting/hadoop-slave1.hadoop%2C60020%2C1494554366239.1494568780692 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-slave1.hadoop%2C60020%2C1494554366239.1494568780692
2017-05-12 06:23:17,645 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692
2017-05-12 06:23:17,645 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717 entered state: DONE hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,669 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave1.hadoop,60020,1494554366239-splitting] in 4333ms
2017-05-12 06:23:17,669 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.RegionStates: Adding to processed servers hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 06:23:17,670 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] handler.ServerShutdownHandler: Reassigning 0 region(s) that hadoop-slave1.hadoop,60020,1494554366239 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 06:23:17,670 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] master.DeadServer: Finished processing hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 06:23:17,670 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-3] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-slave1.hadoop,60020,1494554366239
2017-05-12 06:23:17,685 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224-splitting/hadoop-slave2.hadoop%2C60020%2C1494554366224.1494568780717 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-slave2.hadoop%2C60020%2C1494554366224.1494568780717
2017-05-12 06:23:17,686 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717
2017-05-12 06:23:17,686 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-slave1.hadoop%2C60020%2C1494554366239-splitting%2Fhadoop-slave1.hadoop%252C60020%252C1494554366239.1494568780692
2017-05-12 06:23:17,690 WARN  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224-splitting
2017-05-12 06:23:17,690 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-slave2.hadoop,60020,1494554366224-splitting] in 4348ms
2017-05-12 06:23:17,690 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.RegionStates: Adding to processed servers hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 06:23:17,691 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Reassigning 0 region(s) that hadoop-slave2.hadoop,60020,1494554366224 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 06:23:17,691 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] master.DeadServer: Finished processing hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 06:23:17,691 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-2] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-slave2.hadoop,60020,1494554366224
2017-05-12 06:23:17,698 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-slave2.hadoop%2C60020%2C1494554366224-splitting%2Fhadoop-slave2.hadoop%252C60020%252C1494554366224.1494568780717
2017-05-12 06:23:17,698 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683 entered state: DONE hadoop-master,60020,1494570184588
2017-05-12 06:23:17,710 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347-splitting/hadoop-master%2C60020%2C1494554366347.1494568780683 to hdfs://hadoop-master:9000/hbase/oldWALs/hadoop-master%2C60020%2C1494554366347.1494568780683
2017-05-12 06:23:17,711 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683
2017-05-12 06:23:17,722 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fhadoop-master%2C60020%2C1494554366347-splitting%2Fhadoop-master%252C60020%252C1494554366347.1494568780683
2017-05-12 06:23:17,736 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://hadoop-master:9000/hbase/WALs/hadoop-master,60020,1494554366347-splitting] in 4422ms
2017-05-12 06:23:17,736 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.RegionStates: Adding to processed servers hadoop-master,60020,1494554366347
2017-05-12 06:23:17,736 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Reassigning 1 region(s) that hadoop-master,60020,1494554366347 was carrying (and 0 regions(s) that were opening on this server)
2017-05-12 06:23:17,736 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2017-05-12 06:23:17,738 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: Timeout-on-RIT=151000
2017-05-12 06:23:17,738 DEBUG [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] master.AssignmentManager: Assigning 1 region(s) to hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,740 DEBUG [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] zookeeper.ZKAssign: master:60000-0x15bfb5322060001, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Async create of unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad with OFFLINE state
2017-05-12 06:23:17,761 DEBUG [main-EventThread] master.OfflineCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494570193184, server=hadoop-master,60020,1494554366347}, server=hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,762 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494570193184, server=hadoop-master,60020,1494554366347}, server=hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,765 INFO  [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] master.AssignmentManager: hadoop-slave2.hadoop,60020,1494570183776 unassigned znodes=1 of total=1
2017-05-12 06:23:17,765 INFO  [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OFFLINE, ts=1494570197740, server=hadoop-master,60020,1494554366347} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494570197765, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:17,766 DEBUG [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] master.ServerManager: New admin connection to hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,832 DEBUG [hadoop-master,60000,1494570183603-GeneralBulkAssigner-2] master.AssignmentManager: Bulk assigning done for hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:17,832 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.GeneralBulkAssigner: bulk assigning total 1 regions to 3 servers, took 94ms, with 1 regions still in transition
2017-05-12 06:23:17,832 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.AssignmentManager: Bulk assigning done
2017-05-12 06:23:17,832 DEBUG [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] master.DeadServer: Finished processing hadoop-master,60020,1494554366347
2017-05-12 06:23:17,832 INFO  [MASTER_SERVER_OPERATIONS-hadoop-master:60000-0] handler.ServerShutdownHandler: Finished processing of shutdown of hadoop-master,60020,1494554366347
2017-05-12 06:23:17,862 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=hadoop-slave2.hadoop,60020,1494570183776, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494570197765, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:17,862 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=PENDING_OPEN, ts=1494570197765, server=hadoop-slave2.hadoop,60020,1494570183776} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494570197862, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:18,103 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=hadoop-slave2.hadoop,60020,1494570183776, region=c9b8ca3abb5540b1eceabe95fa2a16ad, current_state={c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494570197862, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:18,103 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPENING, ts=1494570197862, server=hadoop-slave2.hadoop,60020,1494570183776} to {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494570198103, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:18,103 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of c9b8ca3abb5540b1eceabe95fa2a16ad from hadoop-slave2.hadoop,60020,1494570183776; deleting unassigned node
2017-05-12 06:23:18,117 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x15bfb5322060001, quorum=hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181, baseZNode=/hbase Deleted unassigned node c9b8ca3abb5540b1eceabe95fa2a16ad in expected state RS_ZK_REGION_OPENED
2017-05-12 06:23:18,117 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1494407566345.c9b8ca3abb5540b1eceabe95fa2a16ad. deleted, state: {c9b8ca3abb5540b1eceabe95fa2a16ad state=OPEN, ts=1494570198103, server=hadoop-slave2.hadoop,60020,1494570183776}
2017-05-12 06:23:18,117 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined c9b8ca3abb5540b1eceabe95fa2a16ad on hadoop-slave2.hadoop,60020,1494570183776
2017-05-12 06:23:18,199 DEBUG [master:hadoop-master:60000] client.ClientSmallScanner: Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-05-12 06:23:18,270 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2017-05-12 06:23:18,288 INFO  [master:hadoop-master:60000] master.HMaster: Master has completed initialization
2017-05-12 06:23:18,288 INFO  [master:hadoop-master:60000] zookeeper.ZooKeeperWatcher: not a secure deployment, proceeding
2017-05-12 06:23:18,289 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2017-05-12 06:23:18,289 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-05-12 06:31:06,772 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x6a7438e8] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x5bfb5322300001
2017-05-12 06:31:06,785 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x6a7438e8] zookeeper.ZooKeeper: Session: 0x5bfb5322300001 closed
2017-05-12 06:31:06,785 INFO  [master:hadoop-master:60000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2017-05-12 06:31:06,785 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x6a7438e8] client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
2017-05-12 06:34:07,132 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494554366347.1494568780683
2017-05-12 06:34:07,135 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494554366239.1494568780692
2017-05-12 06:34:07,136 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494554366224.1494568780717
2017-05-12 07:34:07,162 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-master%2C60020%2C1494570184588.1494570187892
2017-05-12 07:34:07,175 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494570183952.1494570187855
2017-05-12 07:34:07,176 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494570183952.1494570192661.meta
2017-05-12 07:34:07,176 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494570183952.1494570198066.meta
2017-05-12 07:34:07,176 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave1.hadoop%2C60020%2C1494570183952.1494573798247.meta
2017-05-12 07:34:07,176 DEBUG [master:hadoop-master:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: hadoop-slave2.hadoop%2C60020%2C1494570183776.1494570187847
